{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2: Merging and regular expressions\n",
    "\n",
    "**Total points (without extra credit)**: 30 \n",
    "\n",
    "**Background on the policy context**: here, we're going to use two datasets to practice reshaping, merging, and regular expression patterns. Both datasets relate to the broader issue of which employers might be violating the rights of temporary guestworkers granted visas under the H-2A program. Here are some articles about potential exploitation of guestworkers by firms and inequality caused by minimal oversight:\n",
    "\n",
    "- News media coverage of labor abuses of temporary guestworkers: https://www.buzzfeednews.com/article/kenbensinger/the-pushovers \n",
    "- GAO report on labor abuses of temporary guestworkers: https://www.gao.gov/products/gao-15-154\n",
    "\n",
    "The following datasets are located in `pset2_inputdata` (need to unzip): \n",
    "\n",
    "- `jobs_clean`: a dataset of guestworker jobs posted by many employers, some of whom have been debarred (banned) from the program for labor abuses; others not debarred\n",
    "- `debar`: a dataset of employers who committed violations of labor regulations meant to protect temporary guestworkers \n",
    "\n",
    "\n",
    "You can view a codebook here: https://docs.google.com/spreadsheets/d/1rF9GJEC8pPKxipD0TsoG9DVdqz3EJ-b-BHEtyioAX7I/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reshaping data (13 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the following dataset stored in `pset2_inputdata`: `debar.csv`\n",
    "\n",
    "This represents employers temporarily banned from hiring workers (debar.csv); call this `debar`\n",
    "\n",
    "\n",
    "View the head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City, State</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J&amp;J Harvesting</td>\n",
       "      <td>Leads, ND</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>1/19/2014</td>\n",
       "      <td>1/18/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stahlman Apiaries, Inc</td>\n",
       "      <td>Selby, SD</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>2/19/2015</td>\n",
       "      <td>2/14/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trust Nursery</td>\n",
       "      <td>Pulaski, NY</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3/21/2014</td>\n",
       "      <td>3/20/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anton Fertilizer Inc.</td>\n",
       "      <td>Dighton, KS</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>3/30/2014</td>\n",
       "      <td>3/29/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great Plains Fluid Service, Inc.</td>\n",
       "      <td>Greensburg, KS</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>3/30/2014</td>\n",
       "      <td>3/29/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Promax Inc.</td>\n",
       "      <td>Whitewater, KS</td>\n",
       "      <td>Failure to Hire U.S. workers</td>\n",
       "      <td>2 years</td>\n",
       "      <td>5/15/2014</td>\n",
       "      <td>5/14/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Annabella Land &amp; Cattle</td>\n",
       "      <td>Annabella, UT</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>5/9/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autumn Hill Orchard</td>\n",
       "      <td>Groton, MA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/5/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caddo Creek Ranch, dba Paradise Ranch</td>\n",
       "      <td>Caddo, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>7/19/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yolanda Chavez</td>\n",
       "      <td>Santa Maria, CA</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>7/22/2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name      City, State  \\\n",
       "0                         J&J Harvesting        Leads, ND   \n",
       "1                 Stahlman Apiaries, Inc        Selby, SD   \n",
       "2                          Trust Nursery      Pulaski, NY   \n",
       "3                  Anton Fertilizer Inc.      Dighton, KS   \n",
       "4       Great Plains Fluid Service, Inc.   Greensburg, KS   \n",
       "5                            Promax Inc.   Whitewater, KS   \n",
       "6                Annabella Land & Cattle    Annabella, UT   \n",
       "7                    Autumn Hill Orchard       Groton, MA   \n",
       "8  Caddo Creek Ranch, dba Paradise Ranch        Caddo, TX   \n",
       "9                         Yolanda Chavez  Santa Maria, CA   \n",
       "\n",
       "                                        Violation Duration Start date  \\\n",
       "0  Failure to respond to audit (partial response)  2 years  1/19/2014   \n",
       "1  Failure to respond to audit (partial response)   1 year  2/19/2015   \n",
       "2  Failure to respond to audit (partial response)   1 year  3/21/2014   \n",
       "3       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
       "4       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
       "5                    Failure to Hire U.S. workers  2 years  5/15/2014   \n",
       "6                                     Non Payment   1 year   5/9/2014   \n",
       "7       Failure to respond to audit (no response)  2 years   7/6/2014   \n",
       "8  Failure to respond to audit (partial response)  2 years  7/20/2014   \n",
       "9                                     Non Payment   1 year  7/23/2014   \n",
       "\n",
       "    End date  \n",
       "0  1/18/2016  \n",
       "1  2/14/2016  \n",
       "2  3/20/2015  \n",
       "3  3/29/2016  \n",
       "4  3/29/2016  \n",
       "5  5/14/2016  \n",
       "6   5/9/2015  \n",
       "7   7/5/2016  \n",
       "8  7/19/2016  \n",
       "9  7/22/2015  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load in the dataset and call it debar\n",
    "debar  = pd.read_csv('debar.csv')\n",
    "\n",
    "#view the head\n",
    "debar.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 (1 point)\n",
    "\n",
    "Print the number of rows in `debar` versus the number of unique employer names (`Name`). Is there one row per employer or multiple rows for some employers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use len in order to print the number of rows in debar\n",
    "len(debar)\n",
    "\n",
    "#use .nunique() to print the number of unique employer names\n",
    "debar.Name.nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 114 rows and only 98 unique employer names, therefore there are multiple rows for some employers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Investigating duplicated rows (2 points)\n",
    "\n",
    "A. Create a new column in `debar`--`is_repeated`-- that tells us whether an employer (`Name`) is repeated > 1 times\n",
    "\n",
    "*Hint*: there are multiple ways to solve this but some possibilities to get the list of names that are repeated are:\n",
    "- Using value_counts() on the `Name` variable and extracting the index from that value counts \n",
    "- Using groupby to count the rows attached to one name\n",
    "\n",
    "B. Print the rows where `is_repeated == True` and interpret\n",
    "\n",
    "C. Subset to the rows where `is_repeated == True` and save that data as `mult_debar`. Print the head() and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City, State</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "      <th>count</th>\n",
       "      <th>is_repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J&amp;J Harvesting</td>\n",
       "      <td>Leads, ND</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>1/19/2014</td>\n",
       "      <td>1/18/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stahlman Apiaries, Inc</td>\n",
       "      <td>Selby, SD</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>2/19/2015</td>\n",
       "      <td>2/14/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trust Nursery</td>\n",
       "      <td>Pulaski, NY</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>3/21/2014</td>\n",
       "      <td>3/20/2015</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anton Fertilizer Inc.</td>\n",
       "      <td>Dighton, KS</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>3/30/2014</td>\n",
       "      <td>3/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great Plains Fluid Service, Inc.</td>\n",
       "      <td>Greensburg, KS</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>3/30/2014</td>\n",
       "      <td>3/29/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Promax Inc.</td>\n",
       "      <td>Whitewater, KS</td>\n",
       "      <td>Failure to Hire U.S. workers</td>\n",
       "      <td>2 years</td>\n",
       "      <td>5/15/2014</td>\n",
       "      <td>5/14/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Annabella Land &amp; Cattle</td>\n",
       "      <td>Annabella, UT</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>5/9/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autumn Hill Orchard</td>\n",
       "      <td>Groton, MA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/5/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caddo Creek Ranch, dba Paradise Ranch</td>\n",
       "      <td>Caddo, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>7/19/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yolanda Chavez</td>\n",
       "      <td>Santa Maria, CA</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>7/23/2014</td>\n",
       "      <td>7/22/2015</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name      City, State  \\\n",
       "0                         J&J Harvesting        Leads, ND   \n",
       "1                 Stahlman Apiaries, Inc        Selby, SD   \n",
       "2                          Trust Nursery      Pulaski, NY   \n",
       "3                  Anton Fertilizer Inc.      Dighton, KS   \n",
       "4       Great Plains Fluid Service, Inc.   Greensburg, KS   \n",
       "5                            Promax Inc.   Whitewater, KS   \n",
       "6                Annabella Land & Cattle    Annabella, UT   \n",
       "7                    Autumn Hill Orchard       Groton, MA   \n",
       "8  Caddo Creek Ranch, dba Paradise Ranch        Caddo, TX   \n",
       "9                         Yolanda Chavez  Santa Maria, CA   \n",
       "\n",
       "                                        Violation Duration Start date  \\\n",
       "0  Failure to respond to audit (partial response)  2 years  1/19/2014   \n",
       "1  Failure to respond to audit (partial response)   1 year  2/19/2015   \n",
       "2  Failure to respond to audit (partial response)   1 year  3/21/2014   \n",
       "3       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
       "4       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
       "5                    Failure to Hire U.S. workers  2 years  5/15/2014   \n",
       "6                                     Non Payment   1 year   5/9/2014   \n",
       "7       Failure to respond to audit (no response)  2 years   7/6/2014   \n",
       "8  Failure to respond to audit (partial response)  2 years  7/20/2014   \n",
       "9                                     Non Payment   1 year  7/23/2014   \n",
       "\n",
       "    End date  count  is_repeated  \n",
       "0  1/18/2016      1        False  \n",
       "1  2/14/2016      1        False  \n",
       "2  3/20/2015      1        False  \n",
       "3  3/29/2016      1        False  \n",
       "4  3/29/2016      1        False  \n",
       "5  5/14/2016      1        False  \n",
       "6   5/9/2015      2         True  \n",
       "7   7/5/2016      2         True  \n",
       "8  7/19/2016      2         True  \n",
       "9  7/22/2015      1        False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A \n",
    "\n",
    "#counts how many times each value appears in the name column \n",
    "name_counts = debar['Name'].value_counts().reset_index()\n",
    "\n",
    "#renames the columns in name_counts\n",
    "name_counts.columns = ['Name', 'count']\n",
    "\n",
    "#update the df\n",
    "debar = debar.merge(name_counts, on='Name', how='left')\n",
    "\n",
    "#add new column in debar\n",
    "debar['is_repeated'] = debar['count'] > 1\n",
    "\n",
    "debar.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City, State</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "      <th>count</th>\n",
       "      <th>is_repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Annabella Land &amp; Cattle</td>\n",
       "      <td>Annabella, UT</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>5/9/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autumn Hill Orchard</td>\n",
       "      <td>Groton, MA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/5/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caddo Creek Ranch, dba Paradise Ranch</td>\n",
       "      <td>Caddo, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>7/19/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Loewen Harvesting LLC</td>\n",
       "      <td>Brownsville, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>8/19/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rollo Farm Labor Contractor</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>8/23/2014</td>\n",
       "      <td>8/22/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sharon Mathis</td>\n",
       "      <td>Tifton, GA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SRT Farms</td>\n",
       "      <td>Morton, TX</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mark Duncan</td>\n",
       "      <td>Roosevelt, UT</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Maple Ridge Custom Services, LLC</td>\n",
       "      <td>Altheimer, AK</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>F&amp;W Farms</td>\n",
       "      <td>Ingalls, KS</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>12/10/2014</td>\n",
       "      <td>12/9/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cisco Produce Inc.</td>\n",
       "      <td>Cairo, GA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>12/10/2014</td>\n",
       "      <td>12/9/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Old Tree Farms/Verpaalen Custom Service</td>\n",
       "      <td>Volga, SD</td>\n",
       "      <td>WHD Debarment</td>\n",
       "      <td>3 years</td>\n",
       "      <td>12/11/2014</td>\n",
       "      <td>12/10/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rollo Farm Labor Contractor</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>8/23/2014</td>\n",
       "      <td>8/22/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Loewen Harvesting LLC</td>\n",
       "      <td>Brownfield, TX</td>\n",
       "      <td>Impeding the Audit Process – Partial- Response</td>\n",
       "      <td>1 year</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>8/19/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Caddo Creek Ranch, dba Paradise Ranch</td>\n",
       "      <td>Caddo, Texas</td>\n",
       "      <td>Impeding the Audit Process – Partial- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>7/19/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Autumn Hill Orchard</td>\n",
       "      <td>Groton, MA</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/5/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Annabella Land &amp; Cattle</td>\n",
       "      <td>Annabella, Utah</td>\n",
       "      <td>Non-payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>5/8/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Macky and Brad Farms</td>\n",
       "      <td>Plains, TX</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>2/13/2015</td>\n",
       "      <td>2/12/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Old Tree Farms/Verpaalen Custom Service</td>\n",
       "      <td>Volga, SD</td>\n",
       "      <td>Wage Hour Debarment</td>\n",
       "      <td>3 years</td>\n",
       "      <td>12/1/2014</td>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Macky and Brad Farms</td>\n",
       "      <td>Plains, TX</td>\n",
       "      <td>Impeding the Audit Process – Partial- Response</td>\n",
       "      <td>1 year</td>\n",
       "      <td>2/13/2015</td>\n",
       "      <td>2/12/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Cisco Produce Inc.</td>\n",
       "      <td>Cairo, GA</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>12/10/2015</td>\n",
       "      <td>12/9/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>F&amp;W Farms</td>\n",
       "      <td>Ingalls, KS</td>\n",
       "      <td>Impeding the Audit Process – Partial- Response</td>\n",
       "      <td>1 year</td>\n",
       "      <td>12/10/2014</td>\n",
       "      <td>12/9/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Maple Ridge Custom Services, LLC</td>\n",
       "      <td>Altheimer, AR</td>\n",
       "      <td>Impeding the Audit Process – Partial- Response</td>\n",
       "      <td>1 year</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Mark Duncan</td>\n",
       "      <td>Roosevelt, UT</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SRT Farms</td>\n",
       "      <td>Morton, TX</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sharon Mathis</td>\n",
       "      <td>Tifton, GA</td>\n",
       "      <td>Impeding the Audit Process – Non- Response</td>\n",
       "      <td>2 years</td>\n",
       "      <td>11/16/2014</td>\n",
       "      <td>11/15/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Xavier Horne</td>\n",
       "      <td>Lyons, Georgia</td>\n",
       "      <td>Non-payment of certification fee</td>\n",
       "      <td>1 year</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>6/15/2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Xavier Horne</td>\n",
       "      <td>Lyons, Georgia</td>\n",
       "      <td>Failure to respond to audit request</td>\n",
       "      <td>2 years</td>\n",
       "      <td>9/27/2017</td>\n",
       "      <td>9/26/2019</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Dove Creek Farms</td>\n",
       "      <td>Mount Vernon, TX</td>\n",
       "      <td>Failure to respond to audit request</td>\n",
       "      <td>2 years</td>\n",
       "      <td>2/9/2018</td>\n",
       "      <td>2/8/2018</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Turner Farms</td>\n",
       "      <td>Healy, KS</td>\n",
       "      <td>Failure to comply with the employer's obligati...</td>\n",
       "      <td>6 months</td>\n",
       "      <td>7/17/19</td>\n",
       "      <td>2/10/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Dove Creek Farms</td>\n",
       "      <td>Mount Vernon, TX</td>\n",
       "      <td>Failure to Respond to Audit Request</td>\n",
       "      <td>2 years</td>\n",
       "      <td>2/9/2018</td>\n",
       "      <td>2/8/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Turner Farms</td>\n",
       "      <td>Healy, KS</td>\n",
       "      <td>Failure to comply with the employer's obligati...</td>\n",
       "      <td>7 months</td>\n",
       "      <td>7/17/19</td>\n",
       "      <td>2/10/20</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name       City, State  \\\n",
       "6                    Annabella Land & Cattle     Annabella, UT   \n",
       "7                        Autumn Hill Orchard        Groton, MA   \n",
       "8      Caddo Creek Ranch, dba Paradise Ranch         Caddo, TX   \n",
       "11                     Loewen Harvesting LLC   Brownsville, TX   \n",
       "12               Rollo Farm Labor Contractor         Miami, FL   \n",
       "14                             Sharon Mathis        Tifton, GA   \n",
       "15                                 SRT Farms        Morton, TX   \n",
       "16                               Mark Duncan     Roosevelt, UT   \n",
       "17          Maple Ridge Custom Services, LLC     Altheimer, AK   \n",
       "18                                 F&W Farms       Ingalls, KS   \n",
       "19                        Cisco Produce Inc.         Cairo, GA   \n",
       "21   Old Tree Farms/Verpaalen Custom Service         Volga, SD   \n",
       "24               Rollo Farm Labor Contractor         Miami, FL   \n",
       "25                     Loewen Harvesting LLC    Brownfield, TX   \n",
       "28     Caddo Creek Ranch, dba Paradise Ranch      Caddo, Texas   \n",
       "29                       Autumn Hill Orchard        Groton, MA   \n",
       "30                   Annabella Land & Cattle   Annabella, Utah   \n",
       "31                      Macky and Brad Farms        Plains, TX   \n",
       "51   Old Tree Farms/Verpaalen Custom Service         Volga, SD   \n",
       "55                      Macky and Brad Farms        Plains, TX   \n",
       "56                        Cisco Produce Inc.         Cairo, GA   \n",
       "58                                 F&W Farms       Ingalls, KS   \n",
       "59          Maple Ridge Custom Services, LLC     Altheimer, AR   \n",
       "60                               Mark Duncan     Roosevelt, UT   \n",
       "61                                 SRT Farms        Morton, TX   \n",
       "62                             Sharon Mathis        Tifton, GA   \n",
       "73                              Xavier Horne    Lyons, Georgia   \n",
       "89                              Xavier Horne    Lyons, Georgia   \n",
       "103                         Dove Creek Farms  Mount Vernon, TX   \n",
       "106                             Turner Farms         Healy, KS   \n",
       "109                         Dove Creek Farms  Mount Vernon, TX   \n",
       "111                             Turner Farms         Healy, KS   \n",
       "\n",
       "                                             Violation  Duration  Start date  \\\n",
       "6                                          Non Payment    1 year    5/9/2014   \n",
       "7            Failure to respond to audit (no response)   2 years    7/6/2014   \n",
       "8       Failure to respond to audit (partial response)   2 years   7/20/2014   \n",
       "11      Failure to respond to audit (partial response)    1 year   8/20/2014   \n",
       "12           Failure to respond to audit (no response)   2 years   8/23/2014   \n",
       "14           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
       "15           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
       "16           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
       "17      Failure to respond to audit (partial response)   2 years  11/16/2014   \n",
       "18      Failure to respond to audit (partial response)   2 years  12/10/2014   \n",
       "19           Failure to respond to audit (no response)   2 years  12/10/2014   \n",
       "21                                       WHD Debarment   3 years  12/11/2014   \n",
       "24          Impeding the Audit Process – Non- Response   2 years   8/23/2014   \n",
       "25      Impeding the Audit Process – Partial- Response    1 year   8/20/2014   \n",
       "28      Impeding the Audit Process – Partial- Response   2 years   7/20/2014   \n",
       "29          Impeding the Audit Process – Non- Response   2 years    7/6/2014   \n",
       "30                                         Non-payment    1 year    5/9/2014   \n",
       "31           Failure to respond to audit (no response)    1 year   2/13/2015   \n",
       "51                                 Wage Hour Debarment   3 years   12/1/2014   \n",
       "55      Impeding the Audit Process – Partial- Response    1 year   2/13/2015   \n",
       "56          Impeding the Audit Process – Non- Response   2 years  12/10/2015   \n",
       "58      Impeding the Audit Process – Partial- Response    1 year  12/10/2014   \n",
       "59      Impeding the Audit Process – Partial- Response    1 year  11/16/2014   \n",
       "60          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
       "61          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
       "62          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
       "73                    Non-payment of certification fee    1 year   6/16/2016   \n",
       "89                 Failure to respond to audit request   2 years   9/27/2017   \n",
       "103                Failure to respond to audit request   2 years    2/9/2018   \n",
       "106  Failure to comply with the employer's obligati...  6 months     7/17/19   \n",
       "109                Failure to Respond to Audit Request   2 years    2/9/2018   \n",
       "111  Failure to comply with the employer's obligati...  7 months     7/17/19   \n",
       "\n",
       "       End date  count  is_repeated  \n",
       "6      5/9/2015      2         True  \n",
       "7      7/5/2016      2         True  \n",
       "8     7/19/2016      2         True  \n",
       "11    8/19/2015      2         True  \n",
       "12    8/22/2016      2         True  \n",
       "14   11/15/2016      2         True  \n",
       "15   11/15/2016      2         True  \n",
       "16   11/15/2016      2         True  \n",
       "17   11/15/2016      2         True  \n",
       "18    12/9/2016      2         True  \n",
       "19    12/9/2016      2         True  \n",
       "21   12/10/2017      2         True  \n",
       "24    8/22/2016      2         True  \n",
       "25    8/19/2015      2         True  \n",
       "28    7/19/2016      2         True  \n",
       "29     7/5/2016      2         True  \n",
       "30     5/8/2015      2         True  \n",
       "31    2/12/2016      2         True  \n",
       "51    12/1/2017      2         True  \n",
       "55    2/12/2016      2         True  \n",
       "56    12/9/2017      2         True  \n",
       "58    12/9/2015      2         True  \n",
       "59   11/15/2015      2         True  \n",
       "60   11/15/2016      2         True  \n",
       "61   11/15/2016      2         True  \n",
       "62   11/15/2016      2         True  \n",
       "73    6/15/2017      2         True  \n",
       "89    9/26/2019      2         True  \n",
       "103    2/8/2018      2         True  \n",
       "106   2/10/2020      2         True  \n",
       "109    2/8/2020      2         True  \n",
       "111     2/10/20      2         True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "#prints just the rows where is_repeated is true\n",
    "debar[debar[\"is_repeated\"] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPRETATION:\n",
    "\n",
    "-many (but not all) of the repeated entries are from multiple violations \n",
    "\n",
    "-the ones that are not from mulitple violations seem to just be repeats of the same entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City, State</th>\n",
       "      <th>Violation</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start date</th>\n",
       "      <th>End date</th>\n",
       "      <th>count</th>\n",
       "      <th>is_repeated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Annabella Land &amp; Cattle</td>\n",
       "      <td>Annabella, UT</td>\n",
       "      <td>Non Payment</td>\n",
       "      <td>1 year</td>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>5/9/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Autumn Hill Orchard</td>\n",
       "      <td>Groton, MA</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/5/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caddo Creek Ranch, dba Paradise Ranch</td>\n",
       "      <td>Caddo, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>7/19/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Loewen Harvesting LLC</td>\n",
       "      <td>Brownsville, TX</td>\n",
       "      <td>Failure to respond to audit (partial response)</td>\n",
       "      <td>1 year</td>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>8/19/2015</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rollo Farm Labor Contractor</td>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>Failure to respond to audit (no response)</td>\n",
       "      <td>2 years</td>\n",
       "      <td>8/23/2014</td>\n",
       "      <td>8/22/2016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name      City, State  \\\n",
       "6                 Annabella Land & Cattle    Annabella, UT   \n",
       "7                     Autumn Hill Orchard       Groton, MA   \n",
       "8   Caddo Creek Ranch, dba Paradise Ranch        Caddo, TX   \n",
       "11                  Loewen Harvesting LLC  Brownsville, TX   \n",
       "12            Rollo Farm Labor Contractor        Miami, FL   \n",
       "\n",
       "                                         Violation Duration Start date  \\\n",
       "6                                      Non Payment   1 year   5/9/2014   \n",
       "7        Failure to respond to audit (no response)  2 years   7/6/2014   \n",
       "8   Failure to respond to audit (partial response)  2 years  7/20/2014   \n",
       "11  Failure to respond to audit (partial response)   1 year  8/20/2014   \n",
       "12       Failure to respond to audit (no response)  2 years  8/23/2014   \n",
       "\n",
       "     End date  count  is_repeated  \n",
       "6    5/9/2015      2         True  \n",
       "7    7/5/2016      2         True  \n",
       "8   7/19/2016      2         True  \n",
       "11  8/19/2015      2         True  \n",
       "12  8/22/2016      2         True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C\n",
    "\n",
    "#subsets the rows and saves it to mult_debar\n",
    "mult_debar = debar[debar['is_repeated'] == True]\n",
    "\n",
    "#print the head\n",
    "mult_debar.head()\n",
    "\n",
    "#print the shape\n",
    "mult_debar.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Reshape mult_debar to wide to begin filtering out duplicates (4 points)\n",
    "\n",
    "You want to separate out two cases:\n",
    "\n",
    "- Cases where the repeat rows for one employer are due to duplicated data \n",
    "- Cases where the repeat rows for one employer represent repeated violations for different issues\n",
    "\n",
    "There are various ways to check duplicates in this data (eg converting `Violation` to lowercase; replacing spelled-out states with two-dig state codes)\n",
    "\n",
    "We're going to use the simple rule of:\n",
    "\n",
    "- A row is a duplicate if, within an employer (defined by Name + City, State), the Start date for each row's violation is the same \n",
    "\n",
    "To begin to check this, reshape `mult_debar` to a wide dataframe (`mult_debar_wide`) with the following columns, treating the `Name` and `City, State` as the index for the pivot:\n",
    "\n",
    "- Name\n",
    "- City, State\n",
    "- start_date_viol1\n",
    "- start_date_viol2\n",
    "\n",
    "Print the head and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/c7yhx_9j79j6cnh267vvt4gc0000gn/T/ipykernel_8605/1992113892.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mult_debar[\"each_violation\"] = mult_debar.groupby(['Name', 'City, State']).cumcount() +1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>each_violation</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>City, State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Annabella Land &amp; Cattle</th>\n",
       "      <th>Annabella, UT</th>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annabella, Utah</th>\n",
       "      <td>5/9/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autumn Hill Orchard</th>\n",
       "      <th>Groton, MA</th>\n",
       "      <td>7/6/2014</td>\n",
       "      <td>7/6/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Caddo Creek Ranch, dba Paradise Ranch</th>\n",
       "      <th>Caddo, TX</th>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caddo, Texas</th>\n",
       "      <td>7/20/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cisco Produce Inc.</th>\n",
       "      <th>Cairo, GA</th>\n",
       "      <td>12/10/2014</td>\n",
       "      <td>12/10/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dove Creek Farms</th>\n",
       "      <th>Mount Vernon, TX</th>\n",
       "      <td>2/9/2018</td>\n",
       "      <td>2/9/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F&amp;W Farms</th>\n",
       "      <th>Ingalls, KS</th>\n",
       "      <td>12/10/2014</td>\n",
       "      <td>12/10/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Loewen Harvesting LLC</th>\n",
       "      <th>Brownfield, TX</th>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brownsville, TX</th>\n",
       "      <td>8/20/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "each_violation                                                   1           2\n",
       "Name                                  City, State                             \n",
       "Annabella Land & Cattle               Annabella, UT       5/9/2014         NaN\n",
       "                                      Annabella, Utah     5/9/2014         NaN\n",
       "Autumn Hill Orchard                   Groton, MA          7/6/2014    7/6/2014\n",
       "Caddo Creek Ranch, dba Paradise Ranch Caddo, TX          7/20/2014         NaN\n",
       "                                      Caddo, Texas       7/20/2014         NaN\n",
       "Cisco Produce Inc.                    Cairo, GA         12/10/2014  12/10/2015\n",
       "Dove Creek Farms                      Mount Vernon, TX    2/9/2018    2/9/2018\n",
       "F&W Farms                             Ingalls, KS       12/10/2014  12/10/2014\n",
       "Loewen Harvesting LLC                 Brownfield, TX     8/20/2014         NaN\n",
       "                                      Brownsville, TX    8/20/2014         NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since duplicate = if 'Employer' (Name + City,State) and 'Start date' are equal\n",
    "mult_debar[\"each_violation\"] = mult_debar.groupby(['Name', 'City, State'])\n",
    "\n",
    "#reshape mult_debar to a wide df \n",
    "mult_debar_wide = mult_debar.pivot_table(index=['Name', 'City, State'],\n",
    "    columns='each_violation',\n",
    "    values='Start date',\n",
    "    aggfunc='first')\n",
    "\n",
    "#prints the head and shape\n",
    "mult_debar_wide.head(10)\n",
    "mult_debar_wide.shape\n",
    "\n",
    "\n",
    "\n",
    "#dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary to store information\n",
    "employer_dict = {}\n",
    "\n",
    "# List to collect duplicate info\n",
    "debar['duplicate_key'] = None  # Initialize a new column for duplicate marking\n",
    "\n",
    "for index, row in debar.iterrows():\n",
    "    key = (row['Name'], row['City, State'])\n",
    "    start_date = row['Start date']\n",
    "    \n",
    "    if key not in employer_dict:\n",
    "        employer_dict[key] = {}\n",
    "    \n",
    "    if start_date in employer_dict[key]:\n",
    "        # If start date is already recorded, it's a duplicate\n",
    "        debar.loc[index, 'duplicate_key'] = 'duplicate'\n",
    "        employer_dict[key][start_date] += 1\n",
    "    else:\n",
    "        # Record the start date for this employer\n",
    "        employer_dict[key][start_date] = 1\n",
    "        debar.loc[index, 'duplicate_key'] = 'unique'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Filter out duplicates from original debar data (6 points)\n",
    "\n",
    "A. Using `mult_debar_wide`, add a column `is_dup` that takes value of True for cases where start_date_viol1 == start_date_viol2 marking the row as a duplicate\n",
    "\n",
    "B. Going back to the original long-format data you loaded at the beginning- `debar`\n",
    "    - For employers where `is_dup == True` as indicated by your wide-format dataframe, only keep `violnum == viol1`\n",
    "    - For all other employers (so is_dup == False and ones we didnt need to check duplicates for), keep all violnum\n",
    "    - Remove the `is_repeated` column from the `debar` data\n",
    "\n",
    "**Hint**: you can complete part B without a for loop; `pd.concat` with axis = 0 (row binding) is one way\n",
    "\n",
    "Call the resulting dataframe `debar_clean` and print the shape and # of unique employer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merging and regex (17 points total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data on job postings\n",
    "\n",
    "The previous dataset contains a small subset of employers who faced temporary bans due to violations of H-2A program regulations\n",
    "\n",
    "Since most of the bans have expired, we're going to see which of those employers posted new H-2A jobs in the first quarter of 2021 \n",
    "\n",
    "Loading the `jobs_clean.csv` data stored in `pset4_inputdata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'jobs_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##load in the second dataset and call it job_clean\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m job_clean  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobs_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#view the head\u001b[39;00m\n\u001b[1;32m      5\u001b[0m job_clean\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jobs_clean.csv'"
     ]
    }
   ],
   "source": [
    "##load in the second dataset and call it job_clean\n",
    "job_clean  = pd.read_csv('jobs_clean.csv')\n",
    "\n",
    "#view the head\n",
    "job_clean.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Try inner join on employer name  (2 points)\n",
    "\n",
    "- Use the `EMPLOYER_NAME` field of the `jobs` dataset\n",
    "- Use the `Name` field of the `debar_clean` dataset \n",
    "\n",
    "A. Use pd.merge with an inner join on those fields to see whether there are any exact matches. \n",
    "\n",
    "B. If there are exact matches, print the row(s) with exact matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Targeted regex (10 points total)\n",
    "\n",
    "You want to see if you can increase the exact match rate with some basic cleaning of each \n",
    "of the employer name fields in each dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Converting to upper (2 points)\n",
    "\n",
    "A. Convert the `EMPLOYER_NAME` and `Name` fields to uppercase using list comprehension rather than df.varname.str.upper() (it's fine to do a separate list comprehension line for each of the two columns)\n",
    "\n",
    "B. Print a random sample of 15 values of each result\n",
    "\n",
    "C. Assign the full vector of uppercase names back to the original data, writing over the original `EMPLOYER_NAME` and `Name` columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code to turn into uppercase here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code for the random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code for assigning the uppercase names back to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Cleaning up punctuation (4 points)\n",
    "\n",
    "You notice that INC, CO, and LLC are sometimes followed by a period (.) but sometimes not\n",
    "\n",
    "A. For each dataset, write a regex pattern using `re.sub` to remove the . but only if it's preceded by INC, LLC, or CO \n",
    "\n",
    "Make sure LLC, INC, CO remain part of the string but just without the dot\n",
    "\n",
    "B. Test the pattern on the positive and negative example we provide below and print the result. See the Github issue for examples of what to return\n",
    "\n",
    "\n",
    "**Hint**: https://stackoverflow.com/questions/7191209/python-re-sub-replace-with-matched-content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example_1 = \"CISCO PRODUCE INC.\"\n",
    "pos_example_2 = \"AVOYELLES HONEY CO., LLC\"\n",
    "neg_example = \"E.V. RANCH LLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here with the regex pattern for part A\n",
    "\n",
    "## insert your code to use re.sub to apply the pattern to the test cases for part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 (4 points)\n",
    "\n",
    "Use that pattern in conjunction with `re.sub` and list comprehension to clean the employer name columns in each dataset. Save the new columns as `name_clean` in each. Then, use row subsetting to (1) subset to rows that changed names and (2) for:\n",
    "\n",
    "- `debar_clean` print the `Name` and `name_clean` columns\n",
    "- `jobs` print the `EMPLOYER_NAME` and `name_clean` columns\n",
    "\n",
    "Make sure to use the uppercase versions of the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to clean the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to print the head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 More joins and more cleaning (5 points)\n",
    "\n",
    "A. Conduct another inner join between `jobs` and `debar_clean` now using the `name_clean` column; print the result. Did the cleaning result in any more employers matched between the two datasets?\n",
    "\n",
    "B. Create a new column in `debar_clean` called `name_clean_2` that uses regex to take the following name in that dataset:\n",
    "\n",
    "- `SLASH E.V. RANCH LLP` in the `debar_clean` dataset\n",
    "\n",
    "And cleans it up so that it matches with this employer in `jobs`\n",
    "\n",
    "- `SLASH EV RANCH` in the `jobs` dataset\n",
    "\n",
    "Eg a pattern to remove the dots in the EV and the space+LLP-- you can apply the pattern to all employer names in debar_clean (so don't need to worry about only applying it to that one employer)\n",
    "\n",
    "\n",
    "C. Conduct a left join using `name_clean_2` as the join column where the left hand dataframe is `jobs`; right hand dataframe is `debar_clean`, store the result as a dataframe, and print the rows where the merge indicator indicates the row was found in both dataframe\n",
    "\n",
    "**Note**: this manual cleaning process is inefficient and helps motivate why talked about fuzzy matching. Fuzzy matching could recognize that Slash EV ranch is a highly similar string to slash ev ranch llp and match them without us needing to use regex to make the strings identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optional extra credit 1: regex to separate companies from individuals (1 point)\n",
    "\n",
    "You notice some employers in `debar_clean` have both the name of the company and the name of individual, e.g.:\n",
    "    \n",
    "COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\n",
    "\n",
    "Use the uppercase/cleaned `name_clean` in `debar_clean`\n",
    "\n",
    "A. Write a regex pattern that does the following:\n",
    "    - Captures the pattern that occurs before COMPANY if (COMPANY) is in string; so in example above, extracts COUNTY FAIR FARM \n",
    "    - Captures the pattern that occurs before INDIVIDUAL if (INDIVIDUAL) is also in string -- so in above, extracts ANDREW WILLIAMSON (so omit the \"and\")\n",
    "    \n",
    "B. Test the pattern on `pos_example` and `neg_example`-- make sure former returns a list (if using find.all) or match object (if using re.search) with the company name and individual name separated out; make sure latter returns empty\n",
    "    \n",
    "**Hints and resources**: for step A, you can either use re.search, re.match, or re.findall; don't worry about matching B&R Harvesting and Paul Cruz (Individual)\n",
    "\n",
    "- Same regex resources as above\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example = \"COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\"\n",
    "neg_example = \"CISCO PRODUCE INC\"\n",
    "\n",
    "## your code here to define the pattern\n",
    "\n",
    "## your code here to apply it to the pos_example\n",
    "\n",
    "## your code here to apply it to the negative example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Iterate over the `name_clean` column in debar and use regex to create two new columns in `debar_clean`:\n",
    "   - `co_name`: A column for company (full `name_clean` string if no match; pattern before COMPANY if one extracted)\n",
    "   - `ind_name`: A column for individual (full `name_clean` string if no match; pattern before INDIVIDUAL if one extracted)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "D. Print three columns for the rows in `debar_clean` containing the negative example and positive example described above (county fair farm and cisco produce):\n",
    "\n",
    "- `name_clean`\n",
    "- `co_name`\n",
    "- `ind_name`\n",
    "- `Violation`\n",
    "\n",
    "**Note**: as shown in the outcome there may be duplicates of the same company reflecting different violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optional extra credit 2 (up to 3 points)\n",
    "\n",
    "- For 1 point extra credit, create a visualization with 1+ of the existing fields in either the raw `jobs` or `debar` data. We'll be showing cool visualizations in class so use your imagination! Options could include visualizing between-state or over-time variation\n",
    "\n",
    "- For 3 points extra credit instead, geocode the employer addresses in `jobs` and plot the addresses of jobs as points overlaid on top of a map of Georgia \n",
    "    - **Note**: this extra credit involves Googling since we have not yet covered spatial data. \n",
    "        - For discussion of how to geocode addresses -> lat/long, see: https://www.natasshaselvaraj.com/a-step-by-step-guide-on-geocoding-in-python/ \n",
    "        - For discussion of plotting lat/long dots against a map, see this discussion of geopandas: https://towardsdatascience.com/plotting-maps-with-geopandas-428c97295a73\n",
    "    - Relevant columns include `EMPLOYER_ADDRESS_1` \n",
    "    - The geocoding might have a long runtime so feel free to implement it in a separate .py script that you submit alongside your notebook and to just read in the geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
